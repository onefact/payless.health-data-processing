{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edbcd12-4cd2-4453-86c3-0ddd58292185",
   "metadata": {},
   "source": [
    "## Normalizing hospital MRF schemas\n",
    "\n",
    "### Big picture method -- CSV\n",
    "We want to read in a file and approximate its schema. We'll start with CSV files since they're the easiest to work with.\n",
    "\n",
    "Steps:\n",
    "1. Download the first chunk of a csv file. We'll start with just a handful of rows\n",
    "2. Take a guess at its delimiters and quotechars\n",
    "3. Remove any junk information that may be at the top of the file\n",
    "4. Figure out what the header is and what the rows are\n",
    "5. Try to normalize the header columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecadddd-9656-4097-90fe-ccdcdacf92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import requests\n",
    "import csv\n",
    "import chardet\n",
    "\n",
    "from io          import StringIO\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "ddfc2cfa-aa06-4d02-878f-f5a23ca34fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:107.0) Gecko/20100101 Firefox/107.0',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'cross-site',\n",
    "    'Sec-GPC': '1',\n",
    "    'If-Modified-Since': 'Wed, 07 Dec 2022 13:02:20 GMT',\n",
    "    'If-None-Match': 'W/\"63908edc-3879\"',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3387d883-3058-4e36-b178-4fd8d8e4c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = (pl\n",
    "        .read_csv(\n",
    "            file = './paylesshealth/hospitals.csv', \n",
    "            infer_schema_length = 0)\n",
    "        .filter(\n",
    "            pl.col('cdm_url').str.contains('.csv')\n",
    "        )['cdm_url'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "cd04d5bf-7b23-455b-a738-28709654da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience -- will update to be true JSON eventually\n",
    "JSON = dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "03258176-1c5d-4dfe-8a8d-3263b7bb3251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def csv_scan(url: str, n_rows: int = 10) -> JSON:\n",
    "    \"\"\"Download a CSV file and return a dictionary\n",
    "    with its header and some sample rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read first n_rows rows as bytes\n",
    "    data = b''\n",
    "    with requests.get(url, stream = True, headers = headers) as r:\n",
    "        g = r.iter_lines()\n",
    "        for _ in range(n_rows):\n",
    "            chunk = next(g)\n",
    "            data += (chunk + b'\\n')\n",
    "\n",
    "    # Detect the file encoding\n",
    "    enc = chardet.detect(data)['encoding']\n",
    "    \n",
    "    # Detect the CSV schema\n",
    "    chunk = chunk.decode(enc)\n",
    "    dialect = csv.Sniffer().sniff(chunk)\n",
    "    delim = dialect.delimiter\n",
    "    quotechar = dialect.quotechar\n",
    "    \n",
    "    # Create a file object to iterate through\n",
    "    # and parse\n",
    "    content = data.decode(enc)\n",
    "    f = StringIO(content)\n",
    "    reader = csv.reader(f, delimiter = delim, quotechar = quotechar)\n",
    "    rows = [row for row in reader]\n",
    "    \n",
    "    # Identify which of these rows is the header\n",
    "    header_idx = find_header_idx(rows)\n",
    "\n",
    "    # and strip off the junk at the beginning\n",
    "    # of the file\n",
    "    header = rows[header_idx]\n",
    "    rows = rows[header_idx+1:]\n",
    "    \n",
    "    json = {'header': header,\n",
    "            'rows': rows}\n",
    "        \n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1527b17-1821-45c4-b250-d52a091d4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_header_idx(rows: list) -> int:\n",
    "    \"\"\"Finds the most likely header row in a list of rows.\n",
    "    Computes a score for each row by looking for keywords.\n",
    "    The row with the highest score is marked as the header.\n",
    "    \"\"\"\n",
    "    \n",
    "    header_idx = 0\n",
    "    header_score = 0\n",
    "    header_strs = ['cpt', 'drg', 'price', 'desc', 'name', 'payer', 'charge',\n",
    "                   'gross', 'discounted', 'procedure', 'revenue', 'billing',\n",
    "                   'allowable', 'negotiated', 'max', 'inpatient', 'outpatient']\n",
    "    \n",
    "    for idx, row in enumerate(rows):\n",
    "        rowstr = ''.join(row).lower()\n",
    "        score = sum([s in rowstr for s in header_strs])\n",
    "        if score > header_score:\n",
    "            header_idx = idx\n",
    "            header_score = score\n",
    "            \n",
    "    return header_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc9d304-97aa-49d6-8b0f-4e9cc02b64cb",
   "metadata": {},
   "source": [
    "## Normalizing the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "b8aaafb1-0bab-4e8c-992c-1873c3bce9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cols(cols: list) -> list:\n",
    "    \"Map the header column names to normalized names\"\n",
    "    \n",
    "    return [normalize_value(c) for c in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7a7326-7643-4069-9eed-aa182a63fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strfilter(s: str, yes: list, no: list = []) -> bool:\n",
    "    \"\"\"return True if any of the 'yes' values are in s\n",
    "    AND if none of the 'no' values are in s.\n",
    "    \n",
    "    This is a heuristic for matching strings to their normalized\n",
    "    versions.\n",
    "    \n",
    "    E.g. 'Cash Price' -> 'cash'\n",
    "    E.g. 'Cash price calculation method' -> 'unknown'\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.lower()\n",
    "    yes = [y.lower() for y in yes]\n",
    "    no = [n.lower() for n in no]\n",
    "    \n",
    "    if (\n",
    "        any([y in s for y in yes])\n",
    "        and not any([n in s for n in no])\n",
    "    ):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "assert(strfilter('Alec', 'lec'))\n",
    "assert(strfilter('Alec', 'lec', 'B'))\n",
    "assert(strfilter('Cash_Calculation_Method', 'cash'))\n",
    "assert(not strfilter('Cash_Calculation_Method', 'cash', 'method'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "17506d1d-8831-41eb-a827-7c7b23429bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(s: str) -> str:\n",
    "    \"Finds the best guess for normalizing a string s\"\n",
    "    \n",
    "    if strfilter(s, ['gross', 'price'], ['cash', 'min', 'max', 'cpt', 'drg']):\n",
    "        return 'gross'\n",
    "    \n",
    "    if strfilter(s, ['cash'], ['method', 'cpt']):\n",
    "        return 'cash_price'\n",
    "    \n",
    "    if strfilter(s, ['cpt', 'drg', 'code'], ['desc', 'price']):\n",
    "        return 'code'\n",
    "    \n",
    "    if strfilter(s, ['payer'], ['description', 'cash', 'code', 'cpt']):\n",
    "        return 'payer'\n",
    "    \n",
    "    if strfilter(s, ['desc'], ['cash', 'min', 'max']):\n",
    "        return 'description'\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "25aaf4f0-0c52-4310-8d1c-074ee8081fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_normalization(header: list) -> bool:\n",
    "    \"\"\"We should only have one value for each column. If not, \n",
    "    we made a mistake.\n",
    "    \"\"\"\n",
    "    cts = Counter(header)\n",
    "    \n",
    "    try:\n",
    "        cts.pop(None)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if not cts:\n",
    "        return False\n",
    "    \n",
    "    if max(cts.values()) == 1:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "e0751173-fba7-4b28-b2d9-57719c81fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(urls: list, n_rows: int) -> JSON:\n",
    "    \"\"\"Main data pipeline.\"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for url in urls:\n",
    "        \n",
    "        try:\n",
    "            j = csv_scan(url, n_rows)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "            \n",
    "        j['url'] = url\n",
    "        j['header_normalized'] = normalize_cols(j['header'])\n",
    "        j['validated'] = validate_normalization(j['header'])\n",
    "        data.append(j)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "bc5cfe35-e5ca-4417-81c0-49f1c382bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pipeline(csvs[4:10], 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
